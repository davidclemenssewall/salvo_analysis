{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "233aaff4",
   "metadata": {},
   "source": [
    "# salvo_rename_oblique_photos\n",
    "\n",
    "Notebook for renaming the oblique photos using the information from the notes files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae5dd6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pprint\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "149a10ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths\n",
    "mel_path = os.path.join('..', 'melinda-validation-Feb2025')\n",
    "out_path = os.path.join('..', 'export', 'final-upload-data', 'oblique_photos_2024')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c830253f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all day-sites that we have data for\n",
    "in_dirs = [subdir for subdir in os.listdir(mel_path) if re.match(r\"[0-9]{8}\", subdir)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f0994ea1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'P4170002.JPG': [('0', 1)],\n",
      " 'P4170003.JPG': [('5', 1)],\n",
      " 'P4170004.JPG': [('10', 1)],\n",
      " 'P4170005.JPG': [('15', 1)],\n",
      " 'P4170006.JPG': [('20', 1)],\n",
      " 'P4170007.JPG': [('25', 1)],\n",
      " 'P4170008.JPG': [('30', 1)],\n",
      " 'P4170009.JPG': [('35', 1)],\n",
      " 'P4170010.JPG': [('40', 1)],\n",
      " 'P4170011.JPG': [('45', 1)],\n",
      " 'P4170012.JPG': [('50', 1)],\n",
      " 'P4170013.JPG': [('55', 1)],\n",
      " 'P4170014.JPG': [('60', 1)],\n",
      " 'P4170015.JPG': [('65', 1)],\n",
      " 'P4170016.JPG': [('70', 1)],\n",
      " 'P4170017.JPG': [('75', 1)],\n",
      " 'P4170018.JPG': [('80', 1)],\n",
      " 'P4170019.JPG': [('85', 1)],\n",
      " 'P4170020.JPG': [('90', 1)],\n",
      " 'P4170021.JPG': [('95', 1)],\n",
      " 'P4170022.JPG': [('100', 1)],\n",
      " 'P4170023.JPG': [('105', 1)],\n",
      " 'P4170024.JPG': [('110', 1)],\n",
      " 'P4170025.JPG': [('115', 1)],\n",
      " 'P4170026.JPG': [('120', 1)],\n",
      " 'P4170027.JPG': [('125', 1)],\n",
      " 'P4170028.JPG': [('130', 1)],\n",
      " 'P4170029.JPG': [('135', 1)],\n",
      " 'P4170030.JPG': [('140', 1)],\n",
      " 'P4170031.JPG': [('145', 1)],\n",
      " 'P4170032.JPG': [('150', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[0]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eb988185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5110a75f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240419-arm\n",
      "{'P4190043.JPG': [('5', 1)],\n",
      " 'P4190044.JPG': [('10', 1)],\n",
      " 'P4190045.JPG': [('15', 1)],\n",
      " 'P4190046.JPG': [('20', 1)],\n",
      " 'P4190047.JPG': [('25', 1)],\n",
      " 'P4190048.JPG': [('30', 1)],\n",
      " 'P4190049.JPG': [('35', 1)],\n",
      " 'P4190050.JPG': [('40', 1)],\n",
      " 'P4190051.JPG': [('45', 1)],\n",
      " 'P4190052.JPG': [('50', 1)],\n",
      " 'P4190053.JPG': [('55', 1)],\n",
      " 'P4190054.JPG': [('60', 1)],\n",
      " 'P4190055.JPG': [('65', 1)],\n",
      " 'P4190056.JPG': [('70', 1)],\n",
      " 'P4190057.JPG': [('75', 1)],\n",
      " 'P4190058.JPG': [('80', 1)],\n",
      " 'P4190059.JPG': [('85', 1)],\n",
      " 'P4190060.JPG': [('90', 1)],\n",
      " 'P4190061.JPG': [('95', 1)],\n",
      " 'P4190062.JPG': [('100', 1)],\n",
      " 'P4190063.JPG': [('105', 1)],\n",
      " 'P4190064.JPG': [('110', 1)],\n",
      " 'P4190065.JPG': [('115', 1)],\n",
      " 'P4190066.JPG': [('120', 1)],\n",
      " 'P4190067.JPG': [('125', 1)],\n",
      " 'P4190068.JPG': [('130', 1)],\n",
      " 'P4190069.JPG': [('135', 1)],\n",
      " 'P4190070.JPG': [('140', 1)],\n",
      " 'P4190071.JPG': [('145', 1)],\n",
      " 'P4190072.JPG': [('150', 1)],\n",
      " 'P4190073.JPG': [('155', 1)],\n",
      " 'P4190074.JPG': [('160', 1)],\n",
      " 'P4190075.JPG': [('165', 1)],\n",
      " 'P4190076.JPG': [('170', 1)],\n",
      " 'P4190077.JPG': [('175', 1)],\n",
      " 'P4190078.JPG': [('180', 1)],\n",
      " 'P4190079.JPG': [('185', 1)],\n",
      " 'P4190080.JPG': [('190', 1)],\n",
      " 'P4190081.JPG': [('195', 1)],\n",
      " 'P4190082.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[1]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0b9da27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "da203d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240420-beo\n",
      "{'P4200084.JPG': [('0', 1)],\n",
      " 'P4200085.JPG': [('5', 1)],\n",
      " 'P4200086.JPG': [('10', 1)],\n",
      " 'P4200087.JPG': [('15', 1)],\n",
      " 'P4200088.JPG': [('20', 1)],\n",
      " 'P4200089.JPG': [('25', 1)],\n",
      " 'P4200090.JPG': [('30', 1)],\n",
      " 'P4200091.JPG': [('35', 1)],\n",
      " 'P4200092.JPG': [('40', 1)],\n",
      " 'P4200093.JPG': [('45', 1)],\n",
      " 'P4200094.JPG': [('50', 1)],\n",
      " 'P4200095.JPG': [('55', 1)],\n",
      " 'P4200096.JPG': [('60', 1)],\n",
      " 'P4200097.JPG': [('65', 1)],\n",
      " 'P4200098.JPG': [('70', 1)],\n",
      " 'P4200099.JPG': [('75', 1)],\n",
      " 'P4200100.JPG': [('80', 1)],\n",
      " 'P4200101.JPG': [('85', 1)],\n",
      " 'P4200102.JPG': [('90', 1)],\n",
      " 'P4200103.JPG': [('95', 1)],\n",
      " 'P4200104.JPG': [('100', 1)],\n",
      " 'P4200105.JPG': [('105', 1)],\n",
      " 'P4200106.JPG': [('110', 1)],\n",
      " 'P4200107.JPG': [('115', 1)],\n",
      " 'P4200109.JPG': [('120', 1)],\n",
      " 'P4200110.JPG': [('125', 1)],\n",
      " 'P4200111.JPG': [('130', 1)],\n",
      " 'P4200112.JPG': [('135', 1)],\n",
      " 'P4200113.JPG': [('140', 1)],\n",
      " 'P4200114.JPG': [('145', 1)],\n",
      " 'P4200115.JPG': [('150', 1)],\n",
      " 'P4200116.JPG': [('155', 1)],\n",
      " 'P4200117.JPG': [('160', 1)],\n",
      " 'P4200118.JPG': [('165', 1)],\n",
      " 'P4200119.JPG': [('170', 1)],\n",
      " 'P4200120.JPG': [('175', 1)],\n",
      " 'P4200121.JPG': [('180', 1)],\n",
      " 'P4200122.JPG': [('185', 1)],\n",
      " 'P4200123.JPG': [('190', 1)],\n",
      " 'P4200124.JPG': [('195', 1)],\n",
      " 'P4200125.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[2]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0c6fa315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b511846b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240421-ice\n",
      "{'P4210127.JPG': [('0', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[3]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "550efca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9c422b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240523-beo\n",
      "{'P5230058.JPG': [('0', 1)],\n",
      " 'P5230059.JPG': [('5', 1)],\n",
      " 'P5230060.JPG': [('10', 1)],\n",
      " 'P5230061.JPG': [('15', 1)],\n",
      " 'P5230062.JPG': [('20', 1)],\n",
      " 'P5230063.JPG': [('25', 1)],\n",
      " 'P5230064.JPG': [('30', 1)],\n",
      " 'P5230065.JPG': [('35', 1)],\n",
      " 'P5230066.JPG': [('40', 1)],\n",
      " 'P5230067.JPG': [('45', 1)],\n",
      " 'P5230068.JPG': [('50', 1)],\n",
      " 'P5230069.JPG': [('55', 1)],\n",
      " 'P5230070.JPG': [('60', 1)],\n",
      " 'P5230071.JPG': [('65', 1)],\n",
      " 'P5230072.JPG': [('70', 1)],\n",
      " 'P5230073.JPG': [('75', 1)],\n",
      " 'P5230074.JPG': [('80', 1)],\n",
      " 'P5230075.JPG': [('85', 1)],\n",
      " 'P5230076.JPG': [('90', 1)],\n",
      " 'P5230077.JPG': [('95', 1)],\n",
      " 'P5230078.JPG': [('100', 1)],\n",
      " 'P5230079.JPG': [('105', 1)],\n",
      " 'P5230080.JPG': [('110', 1)],\n",
      " 'P5230081.JPG': [('115', 1)],\n",
      " 'P5230082.JPG': [('120', 1)],\n",
      " 'P5230083.JPG': [('125', 1)],\n",
      " 'P5230084.JPG': [('130', 1)],\n",
      " 'P5230085.JPG': [('135', 1)],\n",
      " 'P5230086.JPG': [('140', 1)],\n",
      " 'P5230087.JPG': [('145', 1)],\n",
      " 'P5230088.JPG': [('150', 1)],\n",
      " 'P5230089.JPG': [('155', 1)],\n",
      " 'P5230090.JPG': [('160', 1)],\n",
      " 'P5230091.JPG': [('165', 1)],\n",
      " 'P5230092.JPG': [('170', 1)],\n",
      " 'P5230093.JPG': [('175', 1)],\n",
      " 'P5230094.JPG': [('180', 1)],\n",
      " 'P5230095.JPG': [('185', 1)],\n",
      " 'P5230096.JPG': [('190', 1)],\n",
      " 'P5230097.JPG': [('195', 1)],\n",
      " 'P5230098.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[4]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "43c15287",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "259ef44c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240524-arm\n",
      "{'P5240140.JPG': [('0', 1)],\n",
      " 'P5240142.JPG': [('5', 1)],\n",
      " 'P5240144.JPG': [('10', 1)],\n",
      " 'P5240146.JPG': [('15', 1)],\n",
      " 'P5240148.JPG': [('20', 1)],\n",
      " 'P5240152.JPG': [('30', 1)],\n",
      " 'P5240154.JPG': [('35', 1)],\n",
      " 'P5240156.JPG': [('40', 1)],\n",
      " 'P5240158.JPG': [('45', 1)],\n",
      " 'P5240160.JPG': [('50', 1)],\n",
      " 'P5240162.JPG': [('55', 1)],\n",
      " 'P5240164.JPG': [('60', 1)],\n",
      " 'P5240166.JPG': [('65', 1)],\n",
      " 'P5240168.JPG': [('70', 1)],\n",
      " 'P5240170.JPG': [('75', 1)],\n",
      " 'P5240172.JPG': [('80', 1)],\n",
      " 'P5240174.JPG': [('85', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[5]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "59d0cd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2af386a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240525-arm\n",
      "{'P5250183.JPG': [('0', 1)],\n",
      " 'P5250184.JPG': [('5', 1)],\n",
      " 'P5250185.JPG': [('10', 1)],\n",
      " 'P5250186.JPG': [('15', 1)],\n",
      " 'P5250187.JPG': [('20', 1)],\n",
      " 'P5250188.JPG': [('25', 1)],\n",
      " 'P5250189.JPG': [('30', 1)],\n",
      " 'P5250190.JPG': [('35', 1)],\n",
      " 'P5250191.JPG': [('40', 1)],\n",
      " 'P5250192.JPG': [('45', 1)],\n",
      " 'P5250193.JPG': [('50', 1)],\n",
      " 'P5250194.JPG': [('55', 1)],\n",
      " 'P5250195.JPG': [('60', 1)],\n",
      " 'P5250196.JPG': [('65', 1)],\n",
      " 'P5250198.JPG': [('70', 1)],\n",
      " 'P5250199.JPG': [('75', 1)],\n",
      " 'P5250200.JPG': [('80', 1)],\n",
      " 'P5250201.JPG': [('85', 1)],\n",
      " 'P5250202.JPG': [('90', 1)],\n",
      " 'P5250203.JPG': [('95', 1)],\n",
      " 'P5250204.JPG': [('100', 1)],\n",
      " 'P5250205.JPG': [('105', 1)],\n",
      " 'P5250206.JPG': [('110', 1)],\n",
      " 'P5250207.JPG': [('115', 1)],\n",
      " 'P5250208.JPG': [('120', 1)],\n",
      " 'P5250209.JPG': [('125', 1)],\n",
      " 'P5250210.JPG': [('135', 1)],\n",
      " 'P5250211.JPG': [('140', 1)],\n",
      " 'P5250212.JPG': [('145', 1)],\n",
      " 'P5250213.JPG': [('150', 1)],\n",
      " 'P5250214.JPG': [('155', 1)],\n",
      " 'P5250216.JPG': [('160', 1)],\n",
      " 'P5250217.JPG': [('165', 1)],\n",
      " 'P5250218.JPG': [('170', 1)],\n",
      " 'P5250219.JPG': [('175', 1)],\n",
      " 'P5250220.JPG': [('180', 1)],\n",
      " 'P5250221.JPG': [('185', 1)],\n",
      " 'P5250222.JPG': [('190', 1)],\n",
      " 'P5250223.JPG': [('195', 1)],\n",
      " 'P5250224.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[6]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1b33a521",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a9e20bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240526-ice\n",
      "{'P5260228.JPG': [('0', 1)],\n",
      " 'P5260229.JPG': [('5', 1)],\n",
      " 'P5260230.JPG': [('10', 1)],\n",
      " 'P5260231.JPG': [('15', 1)],\n",
      " 'P5260232.JPG': [('20', 1)],\n",
      " 'P5260233.JPG': [('25', 1)],\n",
      " 'P5260234.JPG': [('30', 1)],\n",
      " 'P5260236.JPG': [('35', 1)],\n",
      " 'P5260237.JPG': [('40', 1)],\n",
      " 'P5260239.JPG': [('45', 1)],\n",
      " 'P5260240.JPG': [('50', 1)],\n",
      " 'P5260241.JPG': [('55', 1)],\n",
      " 'P5260242.JPG': [('60', 1)],\n",
      " 'P5260243.JPG': [('65', 1)],\n",
      " 'P5260244.JPG': [('70', 1)],\n",
      " 'P5260245.JPG': [('75', 1)],\n",
      " 'P5260246.JPG': [('80', 1)],\n",
      " 'P5260248.JPG': [('95', 1)],\n",
      " 'P5260249.JPG': [('100', 1)],\n",
      " 'P5260250.JPG': [('105', 1)],\n",
      " 'P5260251.JPG': [('110', 1)],\n",
      " 'P5260252.JPG': [('115', 1)],\n",
      " 'P5260253.JPG': [('120', 1)],\n",
      " 'P5260254.JPG': [('125', 1)],\n",
      " 'P5260256.JPG': [('130', 1)],\n",
      " 'P5260257.JPG': [('135', 1)],\n",
      " 'P5260258.JPG': [('140', 1)],\n",
      " 'P5260259.JPG': [('145', 1)],\n",
      " 'P5260260.JPG': [('150', 1)],\n",
      " 'P5260261.JPG': [('155', 1)],\n",
      " 'P5260262.JPG': [('160', 1)],\n",
      " 'P5260264.JPG': [('165', 1)],\n",
      " 'P5260265.JPG': [('170', 1)],\n",
      " 'P5260266.JPG': [('175', 1)],\n",
      " 'P5260267.JPG': [('180', 1)],\n",
      " 'P5260268.JPG': [('185', 1)],\n",
      " 'P5260270.JPG': [('190', 1)],\n",
      " 'P5260272.JPG': [('195', 1)],\n",
      " 'P5260273.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[7]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "001252fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01f27189",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240527-arm\n",
      "{'P5270275.JPG': [('0', 1)],\n",
      " 'P5270276.JPG': [('5', 1)],\n",
      " 'P5270277.JPG': [('10', 1)],\n",
      " 'P5270278.JPG': [('15', 1)],\n",
      " 'P5270279.JPG': [('20', 1)],\n",
      " 'P5270280.JPG': [('25', 1)],\n",
      " 'P5270281.JPG': [('30', 1)],\n",
      " 'P5270282.JPG': [('35', 1)],\n",
      " 'P5270283.JPG': [('40', 1)],\n",
      " 'P5270284.JPG': [('45', 1)],\n",
      " 'P5270285.JPG': [('50', 1)],\n",
      " 'P5270286.JPG': [('55', 1)],\n",
      " 'P5270287.JPG': [('60', 1)],\n",
      " 'P5270288.JPG': [('65', 1)],\n",
      " 'P5270289.JPG': [('70', 1)],\n",
      " 'P5270290.JPG': [('75', 1)],\n",
      " 'P5270291.JPG': [('80', 1)],\n",
      " 'P5270292.JPG': [('85', 1)],\n",
      " 'P5270293.JPG': [('90', 1)],\n",
      " 'P5270294.JPG': [('95', 1)],\n",
      " 'P5270295.JPG': [('100', 1)],\n",
      " 'P5270296.JPG': [('105', 1)],\n",
      " 'P5270297.JPG': [('110', 1)],\n",
      " 'P5270298.JPG': [('115', 1)],\n",
      " 'P5270299.JPG': [('120', 1)],\n",
      " 'P5270300.JPG': [('125', 1)],\n",
      " 'P5270301.JPG': [('130', 1)],\n",
      " 'P5270302.JPG': [('135', 1)],\n",
      " 'P5270304.JPG': [('140', 1)],\n",
      " 'P5270305.JPG': [('145', 1)],\n",
      " 'P5270306.JPG': [('150', 1)],\n",
      " 'P5270307.JPG': [('155', 1)],\n",
      " 'P5270308.JPG': [('160', 1)],\n",
      " 'P5270309.JPG': [('165', 1)],\n",
      " 'P5270310.JPG': [('170', 1)],\n",
      " 'P5270311.JPG': [('175', 1)],\n",
      " 'P5270312.JPG': [('180', 1)],\n",
      " 'P5270313.JPG': [('185', 1)],\n",
      " 'P5270314.JPG': [('190', 1)],\n",
      " 'P5270315.JPG': [('195', 1)],\n",
      " 'P5270316.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[8]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "185ef852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "31d72fb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240529-arm\n",
      "{'P5290378.JPG': [('0', 1)],\n",
      " 'P5290379.JPG': [('5', 1)],\n",
      " 'P5290380.JPG': [('10', 1)],\n",
      " 'P5290381.JPG': [('15', 1)],\n",
      " 'P5290382.JPG': [('25', 1)],\n",
      " 'P5290383.JPG': [('30', 1)],\n",
      " 'P5290384.JPG': [('35', 1)],\n",
      " 'P5290385.JPG': [('40', 1)],\n",
      " 'P5290386.JPG': [('45', 1)],\n",
      " 'P5290387.JPG': [('50', 1)],\n",
      " 'P5290389.JPG': [('55', 1)],\n",
      " 'P5290390.JPG': [('60', 1)],\n",
      " 'P5290391.JPG': [('65', 1)],\n",
      " 'P5290392.JPG': [('70', 1)],\n",
      " 'P5290393.JPG': [('75', 1)],\n",
      " 'P5290394.JPG': [('80', 1)],\n",
      " 'P5290395.JPG': [('85', 1)],\n",
      " 'P5290396.JPG': [('90', 1)],\n",
      " 'P5290398.JPG': [('95', 1)],\n",
      " 'P5290399.JPG': [('100', 1)],\n",
      " 'P5290400.JPG': [('105', 1)],\n",
      " 'P5290402.JPG': [('110', 1)],\n",
      " 'P5290403.JPG': [('115', 1)],\n",
      " 'P5290404.JPG': [('120', 1)],\n",
      " 'P5290405.JPG': [('125', 1)],\n",
      " 'P5290406.JPG': [('130', 1)],\n",
      " 'P5290407.JPG': [('135', 1)],\n",
      " 'P5290408.JPG': [('140', 1)],\n",
      " 'P5290409.JPG': [('145', 1)],\n",
      " 'P5290410.JPG': [('150', 1)],\n",
      " 'P5290411.JPG': [('155', 1)],\n",
      " 'P5290412.JPG': [('160', 1)],\n",
      " 'P5290413.JPG': [('165', 1)],\n",
      " 'P5290414.JPG': [('170', 1)],\n",
      " 'P5290415.JPG': [('175', 1)],\n",
      " 'P5290416.JPG': [('180', 1)],\n",
      " 'P5290417.JPG': [('185', 1)],\n",
      " 'P5290418.JPG': [('190', 1)],\n",
      " 'P5290419.JPG': [('195', 1)],\n",
      " 'P5290420.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[9]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b4977f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e25cc7de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240529-beo\n",
      "{'P5290324.JPG': [('0', 1)],\n",
      " 'P5290325.JPG': [('5', 1)],\n",
      " 'P5290326.JPG': [('10', 1)],\n",
      " 'P5290327.JPG': [('15', 1)],\n",
      " 'P5290328.JPG': [('20', 1)],\n",
      " 'P5290329.JPG': [('25', 1)],\n",
      " 'P5290331.JPG': [('30', 1)],\n",
      " 'P5290332.JPG': [('35', 1)],\n",
      " 'P5290333.JPG': [('40', 1)],\n",
      " 'P5290334.JPG': [('45', 1)],\n",
      " 'P5290335.JPG': [('50', 1)],\n",
      " 'P5290336.JPG': [('55', 1)],\n",
      " 'P5290337.JPG': [('60', 1)],\n",
      " 'P5290338.JPG': [('65', 1)],\n",
      " 'P5290339.JPG': [('70', 1)],\n",
      " 'P5290341.JPG': [('75', 1)],\n",
      " 'P5290342.JPG': [('80', 1)],\n",
      " 'P5290343.JPG': [('85', 1)],\n",
      " 'P5290344.JPG': [('90', 1)],\n",
      " 'P5290345.JPG': [('95', 1)],\n",
      " 'P5290346.JPG': [('100', 1)],\n",
      " 'P5290347.JPG': [('105', 1)],\n",
      " 'P5290348.JPG': [('110', 1)],\n",
      " 'P5290349.JPG': [('115', 1)],\n",
      " 'P5290350.JPG': [('120', 1)],\n",
      " 'P5290351.JPG': [('125', 1)],\n",
      " 'P5290352.JPG': [('130', 1)],\n",
      " 'P5290353.JPG': [('135', 1)],\n",
      " 'P5290354.JPG': [('140', 1)],\n",
      " 'P5290355.JPG': [('145', 1)],\n",
      " 'P5290357.JPG': [('150', 1)],\n",
      " 'P5290359.JPG': [('155', 1)],\n",
      " 'P5290360.JPG': [('160', 1)],\n",
      " 'P5290361.JPG': [('165', 1)],\n",
      " 'P5290362.JPG': [('170', 1)],\n",
      " 'P5290363.JPG': [('175', 1)],\n",
      " 'P5290364.JPG': [('180', 1)],\n",
      " 'P5290365.JPG': [('185', 1)],\n",
      " 'P5290366.JPG': [('190', 1)],\n",
      " 'P5290367.JPG': [('195', 1)],\n",
      " 'P5290369.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[10]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "87113000",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "5a18ab2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240530-ice\n",
      "{'P5300421.JPG': [('0', 1)],\n",
      " 'P5300422.JPG': [('5', 1)],\n",
      " 'P5300423.JPG': [('10', 1)],\n",
      " 'P5300424.JPG': [('15', 1)],\n",
      " 'P5300425.JPG': [('20', 1)],\n",
      " 'P5300426.JPG': [('25', 1)],\n",
      " 'P5300427.JPG': [('30', 1)],\n",
      " 'P5300428.JPG': [('35', 1)],\n",
      " 'P5300429.JPG': [('40', 1)],\n",
      " 'P5300431.JPG': [('45', 1)],\n",
      " 'P5300433.JPG': [('50', 1)],\n",
      " 'P5300434.JPG': [('55', 1)],\n",
      " 'P5300435.JPG': [('60', 1)],\n",
      " 'P5300436.JPG': [('65', 1)],\n",
      " 'P5300437.JPG': [('70', 1)],\n",
      " 'P5300438.JPG': [('75', 1)],\n",
      " 'P5300439.JPG': [('85', 1)],\n",
      " 'P5300442.JPG': [('90', 1)],\n",
      " 'P5300443.JPG': [('95', 1)],\n",
      " 'P5300444.JPG': [('100', 1)],\n",
      " 'P5300445.JPG': [('105', 1)],\n",
      " 'P5300446.JPG': [('110', 1)],\n",
      " 'P5300447.JPG': [('115', 1)],\n",
      " 'P5300448.JPG': [('120', 1)],\n",
      " 'P5300449.JPG': [('125', 1)],\n",
      " 'P5300450.JPG': [('130', 1)],\n",
      " 'P5300451.JPG': [('135', 1)],\n",
      " 'P5300452.JPG': [('140', 1)],\n",
      " 'P5300453.JPG': [('145', 1)],\n",
      " 'P5300454.JPG': [('150', 1)],\n",
      " 'P5300455.JPG': [('155', 1)],\n",
      " 'P5300456.JPG': [('160', 1)],\n",
      " 'P5300457.JPG': [('165', 1)],\n",
      " 'P5300458.JPG': [('170', 1)],\n",
      " 'P5300459.JPG': [('175', 1)],\n",
      " 'P5300460.JPG': [('180', 1)],\n",
      " 'P5300461.JPG': [('185', 1)],\n",
      " 'P5300462.JPG': [('190', 1)],\n",
      " 'P5300463.JPG': [('195', 1)],\n",
      " 'P5300464.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[11]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "96214963",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "355b0036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No line notes in 20240601-arm\n",
      "20240601-arm\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[12]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6a79e4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "62bd825b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240602-beo\n",
      "{'P6020474.JPG': [('0', 1)],\n",
      " 'P6020475.JPG': [('5', 1)],\n",
      " 'P6020476.JPG': [('10', 1)],\n",
      " 'P6020477.JPG': [('15', 1)],\n",
      " 'P6020478.JPG': [('20', 1)],\n",
      " 'P6020479.JPG': [('25', 1)],\n",
      " 'P6020480.JPG': [('30', 1)],\n",
      " 'P6020481.JPG': [('35', 1)],\n",
      " 'P6020482.JPG': [('40', 1)],\n",
      " 'P6020483.JPG': [('45', 1)],\n",
      " 'P6020484.JPG': [('50', 1)],\n",
      " 'P6020485.JPG': [('55', 1)],\n",
      " 'P6020486.JPG': [('60', 1)],\n",
      " 'P6020487.JPG': [('65', 1)],\n",
      " 'P6020488.JPG': [('70', 1)],\n",
      " 'P6020489.JPG': [('75', 1)],\n",
      " 'P6020490.JPG': [('80', 1)],\n",
      " 'P6020491.JPG': [('85', 1)],\n",
      " 'P6020492.JPG': [('90', 1)],\n",
      " 'P6020493.JPG': [('95', 1)],\n",
      " 'P6020494.JPG': [('100', 1)],\n",
      " 'P6020495.JPG': [('105', 1)],\n",
      " 'P6020496.JPG': [('110', 1)],\n",
      " 'P6020497.JPG': [('115', 1)],\n",
      " 'P6020498.JPG': [('120', 1)],\n",
      " 'P6020499.JPG': [('125', 1)],\n",
      " 'P6020500.JPG': [('130', 1)],\n",
      " 'P6020501.JPG': [('135', 1)],\n",
      " 'P6020502.JPG': [('140', 1)],\n",
      " 'P6020503.JPG': [('145', 1)],\n",
      " 'P6020504.JPG': [('150', 1)],\n",
      " 'P6020505.JPG': [('155', 1)],\n",
      " 'P6020506.JPG': [('160', 1)],\n",
      " 'P6020507.JPG': [('165', 1)],\n",
      " 'P6020508.JPG': [('170', 1)],\n",
      " 'P6020509.JPG': [('175', 1)],\n",
      " 'P6020510.JPG': [('180', 1)],\n",
      " 'P6020511.JPG': [('185', 1)],\n",
      " 'P6020512.JPG': [('190', 1)],\n",
      " 'P6020513.JPG': [('195', 1)],\n",
      " 'P6020514.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[13]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "489fd793",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "a2fea1f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240603-arm\n",
      "{'P6030516.JPG': [('0', 1)],\n",
      " 'P6030517.JPG': [('5', 1)],\n",
      " 'P6030518.JPG': [('10', 1)],\n",
      " 'P6030519.JPG': [('15', 1)],\n",
      " 'P6030520.JPG': [('20', 1)],\n",
      " 'P6030521.JPG': [('25', 1)],\n",
      " 'P6030522.JPG': [('30', 1)],\n",
      " 'P6030523.JPG': [('35', 1)],\n",
      " 'P6030524.JPG': [('40', 1)],\n",
      " 'P6030525.JPG': [('45', 1)],\n",
      " 'P6030526.JPG': [('50', 1)],\n",
      " 'P6030527.JPG': [('55', 1)],\n",
      " 'P6030528.JPG': [('60', 1)],\n",
      " 'P6030529.JPG': [('65', 1)],\n",
      " 'P6030530.JPG': [('70', 1)],\n",
      " 'P6030531.JPG': [('75', 1)],\n",
      " 'P6030532.JPG': [('80', 1)],\n",
      " 'P6030533.JPG': [('85', 1)],\n",
      " 'P6030534.JPG': [('90', 1)],\n",
      " 'P6030535.JPG': [('95', 1)],\n",
      " 'P6030536.JPG': [('100', 1)],\n",
      " 'P6030537.JPG': [('105', 1)],\n",
      " 'P6030538.JPG': [('110', 1)],\n",
      " 'P6030539.JPG': [('115', 1)],\n",
      " 'P6030540.JPG': [('120', 1)],\n",
      " 'P6030541.JPG': [('125', 1)],\n",
      " 'P6030542.JPG': [('130', 1)],\n",
      " 'P6030543.JPG': [('135', 1)],\n",
      " 'P6030544.JPG': [('140', 1)],\n",
      " 'P6030545.JPG': [('145', 1)],\n",
      " 'P6030546.JPG': [('150', 1)],\n",
      " 'P6030547.JPG': [('155', 1)],\n",
      " 'P6030548.JPG': [('160', 1)],\n",
      " 'P6030549.JPG': [('165', 1)],\n",
      " 'P6030550.JPG': [('170', 1)],\n",
      " 'P6030551.JPG': [('175', 1)],\n",
      " 'P6030552.JPG': [('180', 1)],\n",
      " 'P6030553.JPG': [('185', 1)],\n",
      " 'P6030554.JPG': [('190', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[14]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "80a37b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "99c8ee84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No line notes in 20240604-arm\n",
      "20240604-arm\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[15]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b9381284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0f4f6c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240604-ice\n",
      "{'P6040555.JPG': [('0', 1)],\n",
      " 'P6040556.JPG': [('5', 1)],\n",
      " 'P6040557.JPG': [('10', 1)],\n",
      " 'P6040558.JPG': [('15', 1)],\n",
      " 'P6040559.JPG': [('20', 1)],\n",
      " 'P6040560.JPG': [('25', 1)],\n",
      " 'P6040561.JPG': [('30', 1)],\n",
      " 'P6040562.JPG': [('35', 1)],\n",
      " 'P6040564.JPG': [('40', 1)],\n",
      " 'P6040565.JPG': [('45', 1)],\n",
      " 'P6040566.JPG': [('50', 1)],\n",
      " 'P6040567.JPG': [('55', 1)],\n",
      " 'P6040568.JPG': [('60', 1)],\n",
      " 'P6040569.JPG': [('65', 1)],\n",
      " 'P6040570.JPG': [('70', 1)],\n",
      " 'P6040571.JPG': [('75', 1)],\n",
      " 'P6040572.JPG': [('80', 1)],\n",
      " 'P6040573.JPG': [('85', 1)],\n",
      " 'P6040574.JPG': [('90', 1)],\n",
      " 'P6040575.JPG': [('95', 1)],\n",
      " 'P6040576.JPG': [('100', 1)],\n",
      " 'P6040577.JPG': [('105', 1)],\n",
      " 'P6040578.JPG': [('110', 1)],\n",
      " 'P6040579.JPG': [('115', 1)],\n",
      " 'P6040580.JPG': [('120', 1)],\n",
      " 'P6040581.JPG': [('125', 1)],\n",
      " 'P6040583.JPG': [('130', 1)],\n",
      " 'P6040582.JPG': [('135', 1)],\n",
      " 'P6040584.JPG': [('140', 1)],\n",
      " 'P6040585.JPG': [('145', 1)],\n",
      " 'P6040586.JPG': [('150', 1)],\n",
      " 'P6040587.JPG': [('155', 1)],\n",
      " 'P6040588.JPG': [('160', 1)],\n",
      " 'P6040589.JPG': [('165', 1)],\n",
      " 'P6040590.JPG': [('170', 1)],\n",
      " 'P6040591.JPG': [('175', 1)],\n",
      " 'P6040593.JPG': [('180', 1)],\n",
      " 'P6040594.JPG': [('185', 1)],\n",
      " 'P6040595.JPG': [('190', 1)],\n",
      " 'P6040596.JPG': [('195', 1)],\n",
      " 'P6040597.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[16]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "174b0b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "afc4da7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240605-arm\n",
      "{'P6050682.JPG': [('0', 1)],\n",
      " 'P6050681.JPG': [('5', 1)],\n",
      " 'P6050680.JPG': [('10', 1)],\n",
      " 'P6050679.JPG': [('15', 1)],\n",
      " 'P6050678.JPG': [('20', 1)],\n",
      " 'P6050677.JPG': [('25', 1)],\n",
      " 'P6050676.JPG': [('30', 1)],\n",
      " 'P6050675.JPG': [('35', 1)],\n",
      " 'P6050674.JPG': [('40', 1)],\n",
      " 'P6050673.JPG': [('45', 1)],\n",
      " 'P6050672.JPG': [('50', 1)],\n",
      " 'P6050671.JPG': [('55', 1)],\n",
      " 'P6050670.JPG': [('60', 1)],\n",
      " 'P6050669.JPG': [('65', 1)],\n",
      " 'P6050668.JPG': [('70', 1)],\n",
      " 'P6050667.JPG': [('75', 1)],\n",
      " 'P6050666.JPG': [('80', 1)],\n",
      " 'P6050665.JPG': [('85', 1)],\n",
      " 'P6050664.JPG': [('90', 1)],\n",
      " 'P6050663.JPG': [('95', 1)],\n",
      " 'P6050662.JPG': [('100', 1)],\n",
      " 'P6050661.JPG': [('105', 1)],\n",
      " 'P6050660.JPG': [('110', 1)],\n",
      " 'P6050659.JPG': [('115', 1)],\n",
      " 'P6050658.JPG': [('120', 1)],\n",
      " 'P6050657.JPG': [('125', 1)],\n",
      " 'P6050656.JPG': [('130', 1)],\n",
      " 'P6050655.JPG': [('135', 1)],\n",
      " 'P6050654.JPG': [('140', 1)],\n",
      " 'P6050653.JPG': [('145', 1)],\n",
      " 'P6050652.JPG': [('150', 1)],\n",
      " 'P6050651.JPG': [('155', 1)],\n",
      " 'P6050650.JPG': [('160', 1)],\n",
      " 'P6050649.JPG': [('165', 1)],\n",
      " 'P6050648.JPG': [('170', 1)],\n",
      " 'P6050647.JPG': [('175', 1)],\n",
      " 'P6050646.JPG': [('180', 1)],\n",
      " 'P6050645.JPG': [('185', 1)],\n",
      " 'P6050644.JPG': [('190', 1)],\n",
      " 'P6050643.JPG': [('195', 1)],\n",
      " 'P6050642.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[17]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "6d89dcd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e2786688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240605-beo\n",
      "{'P6050642.JPG': [('0', 1)],\n",
      " 'P6050641.JPG': [('5', 1)],\n",
      " 'P6050640.JPG': [('10', 1)],\n",
      " 'P6050639.JPG': [('15', 1)],\n",
      " 'P6050638.JPG': [('20', 1)],\n",
      " 'P6050637.JPG': [('25', 1)],\n",
      " 'P6050636.JPG': [('30', 1)],\n",
      " 'P6050635.JPG': [('35', 1)],\n",
      " 'P6050634.JPG': [('40', 1)],\n",
      " 'P6050633.JPG': [('45', 1)],\n",
      " 'P6050632.JPG': [('50', 1)],\n",
      " 'P6050631.JPG': [('55', 1)],\n",
      " 'P6050630.JPG': [('60', 1)],\n",
      " 'P6050629.JPG': [('65', 1)],\n",
      " 'P6050628.JPG': [('70', 1)],\n",
      " 'P6050627.JPG': [('75', 1)],\n",
      " 'P6050626.JPG': [('80', 1)],\n",
      " 'P6050625.JPG': [('85', 1)],\n",
      " 'P6050624.JPG': [('90', 1)],\n",
      " 'P6050623.JPG': [('95', 1)],\n",
      " 'P6050622.JPG': [('100', 1)],\n",
      " 'P6050621.JPG': [('105', 1)],\n",
      " 'P6050620.JPG': [('110', 1)],\n",
      " 'P6050619.JPG': [('115', 1)],\n",
      " 'P6050618.JPG': [('120', 1)],\n",
      " 'P6050617.JPG': [('125', 1)],\n",
      " 'P6050616.JPG': [('130', 1)],\n",
      " 'P6050615.JPG': [('135', 1)],\n",
      " 'P6050614.JPG': [('140', 1)],\n",
      " 'P6050613.JPG': [('145', 1)],\n",
      " 'P6050612.JPG': [('150', 1)],\n",
      " 'P6050611.JPG': [('155', 1)],\n",
      " 'P6050610.JPG': [('160', 1)],\n",
      " 'P6050609.JPG': [('165', 1)],\n",
      " 'P6050608.JPG': [('170', 1)],\n",
      " 'P6050607.JPG': [('175', 1)],\n",
      " 'P6050606.JPG': [('180', 1)],\n",
      " 'P6050605.JPG': [('185', 1)],\n",
      " 'P6050604.JPG': [('190', 1)],\n",
      " 'P6050603.JPG': [('195', 1)],\n",
      " 'P6050602.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[18]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "d515fe91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "a47aacdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240606-arm\n",
      "{'P6060744.JPG': [('0', 1)],\n",
      " 'P6060743.JPG': [('5', 1)],\n",
      " 'P6060742.JPG': [('10', 1)],\n",
      " 'P6060741.JPG': [('15', 1)],\n",
      " 'P6060740.JPG': [('20', 1)],\n",
      " 'P6060739.JPG': [('25', 1)],\n",
      " 'P6060738.JPG': [('30', 1)],\n",
      " 'P6060737.JPG': [('35', 1)],\n",
      " 'P6060736.JPG': [('40', 1)],\n",
      " 'P6060735.JPG': [('45', 1)],\n",
      " 'P6060734.JPG': [('50', 1)],\n",
      " 'P6060733.JPG': [('55', 1)],\n",
      " 'P6060732.JPG': [('60', 1)],\n",
      " 'P6060731.JPG': [('65', 1)],\n",
      " 'P6060730.JPG': [('70', 1)],\n",
      " 'P6060729.JPG': [('75', 1)],\n",
      " 'P6060728.JPG': [('80', 1)],\n",
      " 'P6060727.JPG': [('85', 1)],\n",
      " 'P6060726.JPG': [('90', 1)],\n",
      " 'P6060725.JPG': [('95', 1)],\n",
      " 'P6060724.JPG': [('100', 1)],\n",
      " 'P6060723.JPG': [('105', 1)],\n",
      " 'P6060722.JPG': [('110', 1)],\n",
      " 'P6060721.JPG': [('115', 1)],\n",
      " 'P6060720.JPG': [('120', 1)],\n",
      " 'P6060719.JPG': [('125', 1)],\n",
      " 'P6060718.JPG': [('130', 1)],\n",
      " 'P6060717.JPG': [('135', 1)],\n",
      " 'P6060716.JPG': [('140', 1)],\n",
      " 'P6060715.JPG': [('145', 1)],\n",
      " 'P6060714.JPG': [('150', 1)],\n",
      " 'P6060713.JPG': [('155', 1)],\n",
      " 'P6060712.JPG': [('160', 1)],\n",
      " 'P6060711.JPG': [('165', 1)],\n",
      " 'P6060710.JPG': [('170', 1)],\n",
      " 'P6060709.JPG': [('175', 1)],\n",
      " 'P6060708.JPG': [('180', 1)],\n",
      " 'P6060707.JPG': [('185', 1)],\n",
      " 'P6060706.JPG': [('190', 1)],\n",
      " 'P6060705.JPG': [('195', 1)],\n",
      " 'P6060704.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[19]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "9c87da90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "1f7e2ae1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240607-ice\n",
      "{'P6070745.JPG': [('0', 1)],\n",
      " 'P6070746.JPG': [('5', 1)],\n",
      " 'P6070747.JPG': [('10', 1)],\n",
      " 'P6070748.JPG': [('15', 1)],\n",
      " 'P6070749.JPG': [('20', 1)],\n",
      " 'P6070750.JPG': [('25', 1)],\n",
      " 'P6070751.JPG': [('30', 1)],\n",
      " 'P6070752.JPG': [('35', 1)],\n",
      " 'P6070753.JPG': [('40', 1)],\n",
      " 'P6070754.JPG': [('45', 1)],\n",
      " 'P6070755.JPG': [('50', 1)],\n",
      " 'P6070756.JPG': [('55', 1)],\n",
      " 'P6070757.JPG': [('60', 1)],\n",
      " 'P6070758.JPG': [('65', 1)],\n",
      " 'P6070759.JPG': [('70', 1)],\n",
      " 'P6070760.JPG': [('75', 1)],\n",
      " 'P6070761.JPG': [('80', 1)],\n",
      " 'P6070762.JPG': [('85', 1)],\n",
      " 'P6070763.JPG': [('90', 1)],\n",
      " 'P6070764.JPG': [('95', 1)],\n",
      " 'P6070765.JPG': [('100', 1)],\n",
      " 'P6070766.JPG': [('105', 1)],\n",
      " 'P6070767.JPG': [('110', 1)],\n",
      " 'P6070768.JPG': [('115', 1)],\n",
      " 'P6070769.JPG': [('120', 1)],\n",
      " 'P6070770.JPG': [('125', 1)],\n",
      " 'P6070771.JPG': [('130', 1)],\n",
      " 'P6070772.JPG': [('135', 1)],\n",
      " 'P6070773.JPG': [('140', 1)],\n",
      " 'P6070774.JPG': [('145', 1)],\n",
      " 'P6070775.JPG': [('150', 1)],\n",
      " 'P6070776.JPG': [('155', 1)],\n",
      " 'P6070777.JPG': [('160', 1)],\n",
      " 'P6070778.JPG': [('165', 1)],\n",
      " 'P6070779.JPG': [('170', 1)],\n",
      " 'P6070780.JPG': [('175', 1)],\n",
      " 'P6070781.JPG': [('180', 1)],\n",
      " 'P6070782.JPG': [('185', 1)],\n",
      " 'P6070783.JPG': [('190', 1)],\n",
      " 'P6070784.JPG': [('195', 1)],\n",
      " 'P6070785.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[20]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "2b0bb78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "b7a330a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240608-beo\n",
      "{'P6080808.JPG': [('0', 1)],\n",
      " 'P6080809.JPG': [('5', 1)],\n",
      " 'P6080810.JPG': [('10', 1)],\n",
      " 'P6080811.JPG': [('15', 1)],\n",
      " 'P6080812.JPG': [('20', 1)],\n",
      " 'P6080813.JPG': [('25', 1)],\n",
      " 'P6080814.JPG': [('30', 1)],\n",
      " 'P6080815.JPG': [('35', 1)],\n",
      " 'P6080816.JPG': [('40', 1)],\n",
      " 'P6080817.JPG': [('45', 1)],\n",
      " 'P6080818.JPG': [('50', 1)],\n",
      " 'P6080819.JPG': [('55', 1)],\n",
      " 'P6080820.JPG': [('60', 1)],\n",
      " 'P6080821.JPG': [('65', 1)],\n",
      " 'P6080822.JPG': [('70', 1)],\n",
      " 'P6080823.JPG': [('75', 1)],\n",
      " 'P6080824.JPG': [('80', 1)],\n",
      " 'P6080825.JPG': [('85', 1)],\n",
      " 'P6080826.JPG': [('90', 1)],\n",
      " 'P6080827.JPG': [('95', 1)],\n",
      " 'P6080828.JPG': [('100', 1)],\n",
      " 'P6080829.JPG': [('105', 1)],\n",
      " 'P6080830.JPG': [('110', 1)],\n",
      " 'P6080831.JPG': [('115', 1)],\n",
      " 'P6080832.JPG': [('120', 1)],\n",
      " 'P6080833.JPG': [('125', 1)],\n",
      " 'P6080834.JPG': [('130', 1)],\n",
      " 'P6080835.JPG': [('135', 1)],\n",
      " 'P6080836.JPG': [('140', 1)],\n",
      " 'P6080837.JPG': [('145', 1)],\n",
      " 'P6080838.JPG': [('150', 1)],\n",
      " 'P6080839.JPG': [('155', 1)],\n",
      " 'P6080840.JPG': [('160', 1)],\n",
      " 'P6080841.JPG': [('165', 1)],\n",
      " 'P6080842.JPG': [('170', 1)],\n",
      " 'P6080844.JPG': [('180', 1)],\n",
      " 'P6080846.JPG': [('190', 1)],\n",
      " 'P6080847.JPG': [('195', 1)],\n",
      " 'P6080848.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[21]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a714381b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2cd45a88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240610-arm\n",
      "{'P6100989.JPG': [('0', 1)],\n",
      " 'P6100988.JPG': [('5', 1)],\n",
      " 'P6100987.JPG': [('10', 1)],\n",
      " 'P6100986.JPG': [('15', 1)],\n",
      " 'P6100985.JPG': [('20', 1)],\n",
      " 'P6100984.JPG': [('25', 1)],\n",
      " 'P6100982.JPG': [('30', 1)],\n",
      " 'P6100981.JPG': [('35', 1)],\n",
      " 'P6100980.JPG': [('40', 1)],\n",
      " 'P6100979.JPG': [('45', 1)],\n",
      " 'P6100977.JPG': [('50', 1)],\n",
      " 'P6100976.JPG': [('55', 1)],\n",
      " 'P6100975.JPG': [('60', 1)],\n",
      " 'P6100974.JPG': [('65', 1)],\n",
      " 'P6100973.JPG': [('70', 1)],\n",
      " 'P6100972.JPG': [('75', 1)],\n",
      " 'P6100971.JPG': [('80', 1)],\n",
      " 'P6100970.JPG': [('85', 1)],\n",
      " 'P6100969.JPG': [('90', 1)],\n",
      " 'P6100968.JPG': [('95', 1)],\n",
      " 'P6100967.JPG': [('100', 1)],\n",
      " 'P6100966.JPG': [('105', 1)],\n",
      " 'P6100965.JPG': [('110', 1)],\n",
      " 'P6100964.JPG': [('115', 1)],\n",
      " 'P6100963.JPG': [('120', 1)],\n",
      " 'P6100962.JPG': [('125', 1)],\n",
      " 'P6100961.JPG': [('130', 1)],\n",
      " 'P6100960.JPG': [('135', 1)],\n",
      " 'P6100959.JPG': [('140', 1)],\n",
      " 'P6100958.JPG': [('145', 1)],\n",
      " 'P6100957.JPG': [('150', 1)],\n",
      " 'P6100956.JPG': [('155', 1)],\n",
      " 'P6100955.JPG': [('160', 1)],\n",
      " 'P6100953.JPG': [('165', 1)],\n",
      " 'P6100952.JPG': [('170', 1)],\n",
      " 'P6100951.JPG': [('175', 1)],\n",
      " 'P6100950.JPG': [('180', 1)],\n",
      " 'P6100949.JPG': [('185', 1)],\n",
      " 'P6100948.JPG': [('190', 1)],\n",
      " 'P6100947.JPG': [('195', 1)],\n",
      " 'P6100946.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[22]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "069d54f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "21da2ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240610-ice\n",
      "{'P6100926.JPG': [('0', 1)],\n",
      " 'P6100927.JPG': [('5', 1)],\n",
      " 'P6100928.JPG': [('10', 1)],\n",
      " 'P6100929.JPG': [('15', 1)],\n",
      " 'P6100930.JPG': [('20', 1)],\n",
      " 'P6100931.JPG': [('25', 1)],\n",
      " 'P6100932.JPG': [('30', 1)],\n",
      " 'P6100933.JPG': [('35', 1)],\n",
      " 'P6100934.JPG': [('40', 1)],\n",
      " 'P6100935.JPG': [('45', 1)],\n",
      " 'P6100936.JPG': [('50', 1)],\n",
      " 'P6100937.JPG': [('55', 1)],\n",
      " 'P6100938.JPG': [('60', 1)],\n",
      " 'P6100939.JPG': [('65', 1)],\n",
      " 'P6100940.JPG': [('70', 1)],\n",
      " 'P6100941.JPG': [('75', 1)],\n",
      " 'P6100942.JPG': [('80', 1)],\n",
      " 'P6100943.JPG': [('85', 1)],\n",
      " 'P6100944.JPG': [('90', 1)],\n",
      " 'P6100945.JPG': [('95', 1)],\n",
      " 'P6100917.JPG': [('100', 1)],\n",
      " 'P6100916.JPG': [('105', 1)],\n",
      " 'P6100915.JPG': [('110', 1)],\n",
      " 'P6100914.JPG': [('115', 1)],\n",
      " 'P6100913.JPG': [('120', 1)],\n",
      " 'P6100912.JPG': [('125', 1)],\n",
      " 'P6100911.JPG': [('130', 1)],\n",
      " 'P6100910.JPG': [('135', 1)],\n",
      " 'P6100909.JPG': [('140', 1)],\n",
      " 'P6100908.JPG': [('145', 1)],\n",
      " 'P6100907.JPG': [('150', 1)],\n",
      " 'P6100906.JPG': [('155', 1)],\n",
      " 'P6100905.JPG': [('160', 1)],\n",
      " 'P6100904.JPG': [('165', 1)],\n",
      " 'P6100903.JPG': [('170', 1)],\n",
      " 'P6100902.JPG': [('175', 1)],\n",
      " 'P6100901.JPG': [('180', 1)],\n",
      " 'P6100900.JPG': [('185', 1)],\n",
      " 'P6100899.JPG': [('190', 1)],\n",
      " 'P6100898.JPG': [('195', 1)],\n",
      " 'P6100897.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[23]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0d23d5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "de67983d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240611-beo\n",
      "{'P6110363.JPG': [('0', 1)],\n",
      " 'P6110362.JPG': [('5', 1)],\n",
      " 'P6110361.JPG': [('10', 1)],\n",
      " 'P6110360.JPG': [('15', 1)],\n",
      " 'P6110359.JPG': [('20', 1)],\n",
      " 'P6110358.JPG': [('25', 1)],\n",
      " 'P6110357.JPG': [('30', 1)],\n",
      " 'P6110356.JPG': [('35', 1)],\n",
      " 'P6110355.JPG': [('40', 1)],\n",
      " 'P6110354.JPG': [('45', 1)],\n",
      " 'P6110353.JPG': [('50', 1)],\n",
      " 'P6110352.JPG': [('55', 1)],\n",
      " 'P6110351.JPG': [('60', 1)],\n",
      " 'P6110350.JPG': [('65', 1)],\n",
      " 'P6110349.JPG': [('70', 1)],\n",
      " 'P6110348.JPG': [('75', 1)],\n",
      " 'P6110347.JPG': [('80', 1)],\n",
      " 'P6110346.JPG': [('85', 1)],\n",
      " 'P6110345.JPG': [('90', 1)],\n",
      " 'P6110344.JPG': [('95', 1)],\n",
      " 'P6110342.JPG': [('100', 1)],\n",
      " 'P6110341.JPG': [('105', 1)],\n",
      " 'P6110338.JPG': [('110', 1)],\n",
      " 'P6110337.JPG': [('115', 1)],\n",
      " 'P6110336.JPG': [('120', 1)],\n",
      " 'P6110335.JPG': [('125', 1)],\n",
      " 'P6110334.JPG': [('130', 1)],\n",
      " 'P6110333.JPG': [('135', 1)],\n",
      " 'P6110332.JPG': [('140', 1)],\n",
      " 'P6110331.JPG': [('145', 1)],\n",
      " 'P6110330.JPG': [('150', 1)],\n",
      " 'P6110327.JPG': [('155', 1)],\n",
      " 'P6110326.JPG': [('160', 1)],\n",
      " 'P6110325.JPG': [('165', 1)],\n",
      " 'P6110324.JPG': [('170', 1)],\n",
      " 'P6110323.JPG': [('175', 1)],\n",
      " 'P6110321.JPG': [('180', 1)],\n",
      " 'P6110320.JPG': [('185', 1)],\n",
      " 'P6110319.JPG': [('190', 1)],\n",
      " 'P6110318.JPG': [('195', 1)],\n",
      " 'P6110317.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[24]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name[-4-l_pn:-4]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "e60ab321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "f19960c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240612-arm\n",
      "{'IMG_4232.jpeg': [('0', 1)],\n",
      " 'IMG_4231.jpeg': [('5', 1)],\n",
      " 'IMG_4230.jpeg': [('10', 1)],\n",
      " 'IMG_4229.jpeg': [('15', 1)],\n",
      " 'IMG_4228.jpeg': [('20', 1)],\n",
      " 'IMG_4227.jpeg': [('25', 1)],\n",
      " 'IMG_4226.jpeg': [('30', 1)],\n",
      " 'IMG_4225.jpeg': [('35', 1)],\n",
      " 'IMG_4224.jpeg': [('40', 1)],\n",
      " 'IMG_4223.jpeg': [('45', 1)],\n",
      " 'IMG_4222.jpeg': [('50', 1)],\n",
      " 'IMG_4221.jpeg': [('55', 1)],\n",
      " 'IMG_4219.jpeg': [('60', 1)],\n",
      " 'P6121047.JPG': [('65', 1)],\n",
      " 'P6121046.JPG': [('70', 1)],\n",
      " 'P6121045.JPG': [('75', 1)],\n",
      " 'P6121044.JPG': [('80', 1)],\n",
      " 'P6121043.JPG': [('85', 1)],\n",
      " 'P6121042.JPG': [('90', 1)],\n",
      " 'P6121041.JPG': [('95', 1)],\n",
      " 'P6121040.JPG': [('100', 1)],\n",
      " 'P6121039.JPG': [('105', 1)],\n",
      " 'P6121038.JPG': [('110', 1)],\n",
      " 'P6121037.JPG': [('115', 1)],\n",
      " 'P6121036.JPG': [('120', 1)],\n",
      " 'P6121035.JPG': [('125', 1)],\n",
      " 'P6121034.JPG': [('130', 1)],\n",
      " 'P6121033.JPG': [('135', 1)],\n",
      " 'P6121032.JPG': [('140', 1)],\n",
      " 'P6121031.JPG': [('145', 1)],\n",
      " 'P6121030.JPG': [('150', 1)],\n",
      " 'P6121028.JPG': [('155', 1)],\n",
      " 'P6121027.JPG': [('160', 1)],\n",
      " 'P6121026.JPG': [('165', 1)],\n",
      " 'P6121025.JPG': [('170', 1)],\n",
      " 'P6121024.JPG': [('175', 1)],\n",
      " 'P6121023.JPG': [('180', 1)],\n",
      " 'P6121022.JPG': [('185', 1)],\n",
      " 'P6121021.JPG': [('190', 1)],\n",
      " 'P6121020.JPG': [('195', 1)],\n",
      " 'P6121019.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[25]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name.split('.')[0][-l_pn:]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "c54617f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "3ad858e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240613-ice\n",
      "{'P6131030.JPG': [('0', 1)],\n",
      " 'P6131029.JPG': [('5', 1)],\n",
      " 'P6131028.JPG': [('10', 1)],\n",
      " 'P6131027.JPG': [('15', 1)],\n",
      " 'P6131026.JPG': [('20', 1)],\n",
      " 'P6131025.JPG': [('25', 1)],\n",
      " 'P6131024.JPG': [('30', 1)],\n",
      " 'P6131023.JPG': [('35', 1)],\n",
      " 'P6131022.JPG': [('40', 1)],\n",
      " 'P6131021.JPG': [('45', 1)],\n",
      " 'P6131020.JPG': [('50', 1)],\n",
      " 'P6131019.JPG': [('55', 1)],\n",
      " 'P6131018.JPG': [('60', 1)],\n",
      " 'P6131017.JPG': [('65', 1)],\n",
      " 'P6131016.JPG': [('70', 1)],\n",
      " 'P6131015.JPG': [('75', 1)],\n",
      " 'P6131014.JPG': [('80', 1)],\n",
      " 'P6131013.JPG': [('85', 1)],\n",
      " 'P6131012.JPG': [('90', 1)],\n",
      " 'P6131011.JPG': [('95', 1)],\n",
      " 'P6131010.JPG': [('100', 1)],\n",
      " 'P6131009.JPG': [('105', 1)],\n",
      " 'P6131008.JPG': [('110', 1)],\n",
      " 'P6131007.JPG': [('115', 1)],\n",
      " 'P6131006.JPG': [('120', 1)],\n",
      " 'P6131005.JPG': [('125', 1)],\n",
      " 'P6131004.JPG': [('130', 1)],\n",
      " 'P6131003.JPG': [('135', 1)],\n",
      " 'P6131002.JPG': [('140', 1)],\n",
      " 'P6131001.JPG': [('145', 1)],\n",
      " 'P6131000.JPG': [('150', 1)],\n",
      " 'P6130999.JPG': [('155', 1)],\n",
      " 'P6130998.JPG': [('160', 1)],\n",
      " 'P6130997.JPG': [('165', 1)],\n",
      " 'P6130996.JPG': [('170', 1)],\n",
      " 'P6130995.JPG': [('175', 1)],\n",
      " 'P6130994.JPG': [('180', 1)],\n",
      " 'P6130993.JPG': [('185', 1)],\n",
      " 'P6130992.JPG': [('190', 1)],\n",
      " 'P6130991.JPG': [('195', 1)],\n",
      " 'P6130990.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[26]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name.split('.')[0][-l_pn:]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "768ca320",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "c4141ac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240614-beo\n",
      "{'P6141029.JPG': [('5', 1)],\n",
      " 'P6141028.JPG': [('10', 1)],\n",
      " 'P6141027.JPG': [('15', 1)],\n",
      " 'P6141026.JPG': [('20', 1)],\n",
      " 'P6141025.JPG': [('25', 1)],\n",
      " 'P6141023.JPG': [('30', 1)],\n",
      " 'P6141022.JPG': [('35', 1)],\n",
      " 'P6141021.JPG': [('40', 1)],\n",
      " 'P6141020.JPG': [('45', 1)],\n",
      " 'P6141019.JPG': [('50', 1)],\n",
      " 'P6141018.JPG': [('55', 1)],\n",
      " 'P6141017.JPG': [('60', 1)],\n",
      " 'P6141016.JPG': [('65', 1)],\n",
      " 'P6141015.JPG': [('70', 1)],\n",
      " 'P6141014.JPG': [('80', 1)],\n",
      " 'P6141013.JPG': [('85', 1)],\n",
      " 'P6141012.JPG': [('90', 1)],\n",
      " 'P6141011.JPG': [('95', 1)],\n",
      " 'P6141010.JPG': [('100', 1)],\n",
      " 'P6141009.JPG': [('105', 1)],\n",
      " 'P6141008.JPG': [('110', 1)],\n",
      " 'P6141007.JPG': [('115', 1)],\n",
      " 'P6141006.JPG': [('120', 1)],\n",
      " 'P6141005.JPG': [('125', 1)],\n",
      " 'P6141004.JPG': [('130', 1)],\n",
      " 'P6141003.JPG': [('135', 1)],\n",
      " 'P6141002.JPG': [('140', 1)],\n",
      " 'P6141001.JPG': [('145', 1)],\n",
      " 'P6141000.JPG': [('150', 1)],\n",
      " 'P6140999.JPG': [('155', 1)],\n",
      " 'P6140998.JPG': [('160', 1)],\n",
      " 'P6140997.JPG': [('165', 1)],\n",
      " 'P6140996.JPG': [('170', 1)],\n",
      " 'P6140995.JPG': [('175', 1)],\n",
      " 'P6140994.JPG': [('180', 1)],\n",
      " 'P6140993.JPG': [('185', 1)],\n",
      " 'P6140992.JPG': [('190', 1)],\n",
      " 'P6140991.JPG': [('195', 1)],\n",
      " 'P6140990.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[27]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name.split('.')[0][-l_pn:]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b50724d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "28a201c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240615-arm\n",
      "{'P6151195.JPG': [('0', 1)],\n",
      " 'P6151194.JPG': [('5', 1)],\n",
      " 'P6151193.JPG': [('10', 1)],\n",
      " 'P6151192.JPG': [('15', 1)],\n",
      " 'P6151191.JPG': [('20', 1)],\n",
      " 'P6151190.JPG': [('25', 1)],\n",
      " 'P6151189.JPG': [('30', 1)],\n",
      " 'P6151188.JPG': [('35', 1)],\n",
      " 'P6151187.JPG': [('40', 1)],\n",
      " 'P6151186.JPG': [('45', 1)],\n",
      " 'P6151184.JPG': [('50', 1)],\n",
      " 'P6151183.JPG': [('55', 1)],\n",
      " 'P6151182.JPG': [('60', 1)],\n",
      " 'P6151181.JPG': [('65', 1)],\n",
      " 'P6151180.JPG': [('70', 1)],\n",
      " 'P6151179.JPG': [('75', 1)],\n",
      " 'P6151178.JPG': [('80', 1)],\n",
      " 'P6151177.JPG': [('85', 1)],\n",
      " 'P6151176.JPG': [('90', 1)],\n",
      " 'P6151175.JPG': [('95', 1)],\n",
      " 'P6151174.JPG': [('100', 1)],\n",
      " 'P6151173.JPG': [('105', 1)],\n",
      " 'P6151172.JPG': [('110', 1)],\n",
      " 'P6151171.JPG': [('115', 1)],\n",
      " 'P6151170.JPG': [('120', 1)],\n",
      " 'P6151169.JPG': [('125', 1)],\n",
      " 'P6151168.JPG': [('130', 1)],\n",
      " 'P6151167.JPG': [('135', 1)],\n",
      " 'P6151166.JPG': [('140', 1)],\n",
      " 'P6151165.JPG': [('145', 1)],\n",
      " 'P6151164.JPG': [('150', 1)],\n",
      " 'P6151163.JPG': [('155', 1)],\n",
      " 'P6151162.JPG': [('160', 1)],\n",
      " 'P6151161.JPG': [('165', 1)],\n",
      " 'P6151160.JPG': [('170', 1)],\n",
      " 'P6151159.JPG': [('175', 1)],\n",
      " 'P6151158.JPG': [('180', 1)],\n",
      " 'P6151157.JPG': [('185', 1)],\n",
      " 'P6151156.JPG': [('190', 1)],\n",
      " 'P6151155.JPG': [('195', 1)],\n",
      " 'P6151154.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[28]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name.split('.')[0][-l_pn:]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "ba81e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "cb54590d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240615-ice\n",
      "{'P6151112.JPG': [('0', 1)],\n",
      " 'P6151111.JPG': [('5', 1)],\n",
      " 'P6151110.JPG': [('15', 1)],\n",
      " 'P6151109.JPG': [('20', 1)],\n",
      " 'P6151108.JPG': [('25', 1)],\n",
      " 'P6151107.JPG': [('30', 1)],\n",
      " 'P6151106.JPG': [('35', 1)],\n",
      " 'P6151105.JPG': [('40', 1)],\n",
      " 'P6151104.JPG': [('45', 1)],\n",
      " 'P6151103.JPG': [('50', 1)],\n",
      " 'P6151102.JPG': [('55', 1)],\n",
      " 'P6151101.JPG': [('60', 1)],\n",
      " 'P6151100.JPG': [('65', 1)],\n",
      " 'P6151099.JPG': [('70', 1)],\n",
      " 'P6151098.JPG': [('75', 1)],\n",
      " 'P6151097.JPG': [('80', 1)],\n",
      " 'P6151096.JPG': [('85', 1)],\n",
      " 'P6151095.JPG': [('90', 1)],\n",
      " 'P6151094.JPG': [('95', 1)],\n",
      " 'P6151093.JPG': [('100', 1)],\n",
      " 'P6151092.JPG': [('105', 1)],\n",
      " 'P6151091.JPG': [('110', 1)],\n",
      " 'P6151090.JPG': [('115', 1)],\n",
      " 'P6151089.JPG': [('125', 1)],\n",
      " 'P6151088.JPG': [('130', 1)],\n",
      " 'P6151087.JPG': [('135', 1)],\n",
      " 'P6151086.JPG': [('140', 1)],\n",
      " 'P6151085.JPG': [('145', 1)],\n",
      " 'P6151084.JPG': [('150', 1)],\n",
      " 'P6151083.JPG': [('155', 1)],\n",
      " 'P6151082.JPG': [('160', 1)],\n",
      " 'P6151081.JPG': [('165', 1)],\n",
      " 'P6151080.JPG': [('170', 1)],\n",
      " 'P6151079.JPG': [('175', 1)],\n",
      " 'P6151078.JPG': [('180', 1)],\n",
      " 'P6151077.JPG': [('185', 1)],\n",
      " 'P6151076.JPG': [('190', 1)],\n",
      " 'P6151074.JPG': [('195', 1)],\n",
      " 'P6151072.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[29]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name.split('.')[0][-l_pn:]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fc1b9a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "38430733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240617-arm\n",
      "{'P6171236.JPG': [('0', 1)],\n",
      " 'P6171235.JPG': [('5', 1)],\n",
      " 'P6171234.JPG': [('10', 1)],\n",
      " 'P6171233.JPG': [('15', 1)],\n",
      " 'P6171232.JPG': [('20', 1)],\n",
      " 'P6171231.JPG': [('25', 1)],\n",
      " 'P6171230.JPG': [('30', 1)],\n",
      " 'P6171229.JPG': [('35', 1)],\n",
      " 'P6171228.JPG': [('40', 1)],\n",
      " 'P6171227.JPG': [('45', 1)],\n",
      " 'P6171226.JPG': [('50', 1)],\n",
      " 'P6171225.JPG': [('55', 1)],\n",
      " 'P6171224.JPG': [('60', 1)],\n",
      " 'P6171223.JPG': [('65', 1)],\n",
      " 'P6171222.JPG': [('70', 1)],\n",
      " 'P6171221.JPG': [('75', 1)],\n",
      " 'P6171220.JPG': [('80', 1)],\n",
      " 'P6171219.JPG': [('85', 1)],\n",
      " 'P6171218.JPG': [('90', 1)],\n",
      " 'P6171217.JPG': [('95', 1)],\n",
      " 'P6171216.JPG': [('100', 1)],\n",
      " 'P6171215.JPG': [('105', 1)],\n",
      " 'P6171214.JPG': [('110', 1)],\n",
      " 'P6171213.JPG': [('115', 1)],\n",
      " 'P6171212.JPG': [('120', 1)],\n",
      " 'P6171211.JPG': [('125', 1)],\n",
      " 'P6171210.JPG': [('130', 1)],\n",
      " 'P6171209.JPG': [('135', 1)],\n",
      " 'P6171208.JPG': [('140', 1)],\n",
      " 'P6171207.JPG': [('145', 1)],\n",
      " 'P6171206.JPG': [('150', 1)],\n",
      " 'P6171205.JPG': [('155', 1)],\n",
      " 'P6171204.JPG': [('160', 1)],\n",
      " 'P6171203.JPG': [('165', 1)],\n",
      " 'P6171202.JPG': [('170', 1)],\n",
      " 'P6171201.JPG': [('175', 1)],\n",
      " 'P6171200.JPG': [('180', 1)],\n",
      " 'P6171199.JPG': [('185', 1)],\n",
      " 'P6171198.JPG': [('190', 1)],\n",
      " 'P6171197.JPG': [('195', 1)],\n",
      " 'P6171196.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[30]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name.split('.')[0][-l_pn:]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "15ab5c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6252347b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20240617-beo\n",
      "{'P6171277.JPG': [('0', 1)],\n",
      " 'P6171276.JPG': [('5', 1)],\n",
      " 'P6171275.JPG': [('10', 1)],\n",
      " 'P6171274.JPG': [('15', 1)],\n",
      " 'P6171273.JPG': [('20', 1)],\n",
      " 'P6171272.JPG': [('25', 1)],\n",
      " 'P6171271.JPG': [('30', 1)],\n",
      " 'P6171270.JPG': [('35', 1)],\n",
      " 'P6171269.JPG': [('40', 1)],\n",
      " 'P6171268.JPG': [('45', 1)],\n",
      " 'P6171267.JPG': [('50', 1)],\n",
      " 'P6171266.JPG': [('55', 1)],\n",
      " 'P6171265.JPG': [('60', 1)],\n",
      " 'P6171264.JPG': [('65', 1)],\n",
      " 'P6171263.JPG': [('70', 1)],\n",
      " 'P6171262.JPG': [('75', 1)],\n",
      " 'P6171261.JPG': [('80', 1)],\n",
      " 'P6171260.JPG': [('85', 1)],\n",
      " 'P6171259.JPG': [('90', 1)],\n",
      " 'P6171258.JPG': [('95', 1)],\n",
      " 'P6171257.JPG': [('100', 1)],\n",
      " 'P6171256.JPG': [('105', 1)],\n",
      " 'P6171255.JPG': [('110', 1)],\n",
      " 'P6171254.JPG': [('115', 1)],\n",
      " 'P6171253.JPG': [('120', 1)],\n",
      " 'P6171252.JPG': [('125', 1)],\n",
      " 'P6171251.JPG': [('130', 1)],\n",
      " 'P6171250.JPG': [('135', 1)],\n",
      " 'P6171249.JPG': [('140', 1)],\n",
      " 'P6171248.JPG': [('145', 1)],\n",
      " 'P6171247.JPG': [('150', 1)],\n",
      " 'P6171246.JPG': [('155', 1)],\n",
      " 'P6171245.JPG': [('160', 1)],\n",
      " 'P6171244.JPG': [('165', 1)],\n",
      " 'P6171243.JPG': [('170', 1)],\n",
      " 'P6171242.JPG': [('175', 1)],\n",
      " 'P6171241.JPG': [('180', 1)],\n",
      " 'P6171240.JPG': [('185', 1)],\n",
      " 'P6171239.JPG': [('190', 1)],\n",
      " 'P6171238.JPG': [('195', 1)],\n",
      " 'P6171237.JPG': [('200', 1)]}\n"
     ]
    }
   ],
   "source": [
    "# Load in notes and current photo names\n",
    "subdir = in_dirs[31]\n",
    "\n",
    "datestr = subdir[:8]\n",
    "sitestr = subdir[-3:]\n",
    "locstr = 'line'\n",
    "\n",
    "notes_path = os.path.join(mel_path, subdir, 'asd', \n",
    "                          'salvo_'+sitestr+'_line_asd-notes_'+datestr+'.a1.xlsx')\n",
    "try:\n",
    "    df_notes = pd.read_excel(notes_path, header=5, \n",
    "                             usecols=['Position', 'Photo Number', 'Additional Photos'],\n",
    "                            dtype=str)\n",
    "except FileNotFoundError:\n",
    "    print('No line notes in ' + subdir)\n",
    "\n",
    "photo_names = os.listdir(os.path.join(mel_path, subdir, 'asd', 'photos'))\n",
    "\n",
    "# Then parse the Photo Number column\n",
    "dc_rename = {}\n",
    "rep = 1\n",
    "\n",
    "for i in df_notes.index:\n",
    "    pn = df_notes.at[i, 'Photo Number']\n",
    "    if pd.isna(pn):\n",
    "        continue\n",
    "    l_pn = len(pn)\n",
    "    pos = df_notes.at[i, 'Position']\n",
    "    \n",
    "    # Find all photos that match the photo number at this position\n",
    "    ls_matches = [curr_name for curr_name in photo_names if pn==curr_name.split('.')[0][-l_pn:]]\n",
    "    # for each match, add a tuple to the dc_rename with position and repetition\n",
    "    for match in ls_matches:\n",
    "        if match in dc_rename:\n",
    "            dc_rename[match].append((pos, rep))\n",
    "        else:\n",
    "            dc_rename[match] = [(pos, rep)]\n",
    "\n",
    "print(subdir)\n",
    "# Check for duplicates\n",
    "for key, value in dc_rename.items():\n",
    "    if len(value) != 1:\n",
    "        print('Duplicate!')\n",
    "        print(key)\n",
    "        print(value)\n",
    "        \n",
    "pprint.pp(dc_rename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "da9545d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If no duplicates/duplicates resolved, copy photos\n",
    "for curr_name, pos_rep in dc_rename.items():\n",
    "    posstr = pos_rep[0][0]\n",
    "    repstr = str(pos_rep[0][1])\n",
    "    \n",
    "    # Create new photo name\n",
    "    new_name = 'salvo_'+sitestr+'_'+locstr+'_oblique_'+datestr+'_'+posstr+'_'+repstr+'.JPG'\n",
    "    #print(new_name)\n",
    "    shutil.copy2(os.path.join(mel_path, subdir, 'asd', 'photos', curr_name),\n",
    "                os.path.join(out_path, new_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de6a2a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
